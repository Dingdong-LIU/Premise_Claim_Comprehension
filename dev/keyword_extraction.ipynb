{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key word extraction algorithm for claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from helper_function import count_valid_posts, get_claims, get_premises\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid posts:  (67, 78)\n"
     ]
    }
   ],
   "source": [
    "data_file_path = '../data/v4/Should-I-invest-in-Bitcoin_with_labels_v4_70_filled.json'\n",
    "data_file_path = '../data/v4/Would-you-get-into-a-self-driving-car_v4_70_filled.json'\n",
    "with open(data_file_path, 'r') as f:\n",
    "    file_content = json.load(f)\n",
    "print('Get valid posts: ', count_valid_posts(file_content))\n",
    "claims = get_claims(file_content)\n",
    "premises = get_premises(file_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword extraction algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keyword_extractor import TfIdfExtractor\n",
    "\n",
    "# if_idf = TfIdfExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if_idf.extract_keywords(premises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyBERT Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyword_extractor import KeyBERTExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keybert_extractor = KeyBERTExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keybert_extractor.extract_keywords(premises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Keywords under a certain center claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first build a list of supporting premises\n",
    "claims_with_support = {}\n",
    "for l in get_premises(file_content, return_list_of_strings=False):\n",
    "    # l is a list of dict objects\n",
    "    for o in l:\n",
    "        clm, prm = o['supportClaim'], o['content']\n",
    "        if not clm in claims_with_support:\n",
    "            claims_with_support[clm] = []\n",
    "        claims_with_support[clm].append(prm)\n",
    "\n",
    "claim_center_relation = {}\n",
    "for l in get_claims(file_content, return_list_of_strings=False):\n",
    "    # l is a list of dict objects\n",
    "    for o in l:\n",
    "        clm, sc = o['content'], o['claimCenter']\n",
    "        if not sc in claim_center_relation:\n",
    "            claim_center_relation[sc] = []\n",
    "        claim_center_relation[sc].append(clm)\n",
    "\n",
    "claimCenter_premise = {}\n",
    "for cs, c_list in claim_center_relation.items():\n",
    "    if not cs in claimCenter_premise:\n",
    "        claimCenter_premise[cs] = []\n",
    "    for c in c_list:\n",
    "        if c in claims_with_support:\n",
    "            claimCenter_premise[cs].extend(claims_with_support[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I would. :  12\n",
      "Not at the time of answering. :  8\n",
      "Yes - in a few years it might be safer than me driving. :  9\n",
      "Yes, I really would like to have a self-driving car. :  33\n",
      "Yes. :  13\n",
      "Yes, as soon as they work and are available at a reasonable price. :  6\n",
      "No. It is too early in the technology to be able to trust the self-driving car. :  5\n",
      "I love to drive on a nice day with little or no traffic. At all other times, I'll have my car drive for me. :  9\n",
      "In the case I've described two paragraphs above, I'm really lost as to what fact based evidence could be used to chose the human. :  6\n",
      "Nope. Absolutely not! :  8\n"
     ]
    }
   ],
   "source": [
    "for k,v in claimCenter_premise.items():\n",
    "    print(k, \": \", len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "for k,v in claimCenter_premise.items():\n",
    "    term = {\n",
    "        'content' : k,\n",
    "        'keywords' : []\n",
    "    }\n",
    "    kws = keybert_extractor.extract_keywords(' '.join(v), keep_term=10)\n",
    "    kws.sort(key=lambda a: a[1], reverse=True)\n",
    "    term['keywords'] = kws\n",
    "    output_data.append(term)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claimCenter_premise['It is almost certainly in a bubble.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = keybert_extractor.extract_keywords(' '.join(v), keep_term=15)\n",
    "# x.sort(key=lambda a : a[1])\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = '../data/newest_data(rolling update)/claim center and statistics/bitcoin investment/keywords.json'\n",
    "output_data_path = '../data/newest_data(rolling update)/claim center and statistics/automos driving/keywords.json'\n",
    "with open(output_data_path, 'w') as f:\n",
    "    json.dump(output_data, fp=f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keybert_extractor.extract_keywords(\" \".join(claimCenter_premise['That’s up to you.']), keep_term=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_sentiment = {\n",
    "#     'neutral' : [\n",
    "#         \"It’s not too late to invest.\",\n",
    "#         \"That’s up to you.\",\n",
    "#         \"It depends what your level of disposable income is, how great your assets are, and what other assets you have invested in.\",\n",
    "#         \"The significant thing is to do your own research and comprehend the dangers.\",\n",
    "#         \"Invest in Bitcoin, only if you are okay to loss all.\",\n",
    "#         \"Investing in Bitcoin is viable option especially in a view of current decline of the power of Fiat currencies.\",\n",
    "#         \"If you are willing to take the risk, first make sure you understand what you are investing in and have a crypto investment strategy\",\n",
    "#     ],\n",
    "#     \"positive\" : [\n",
    "#         \"I would say YES!\",\n",
    "#         \"Of course you should\",\n",
    "#     ],\n",
    "#     \"negative\" : [\n",
    "#         \"Bitcoin is pretty useless. But so is gold.\",\n",
    "#         \"Cryto currency is an extremely high-hazard venture, and CFDs bought on margin are significantly more hazardous.\",\n",
    "#         \"It is almost certainly in a bubble.\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# with open('../data/newest_data(rolling update)/claim center and statistics/bitcoin investment/stance_count.json', 'w') as f:\n",
    "#     json.dump(sentence_sentiment, f, indent=4)\n",
    "\n",
    "sentence_sentiment_path = '../data/newest_data(rolling update)/claim center and statistics/bitcoin investment/stance_count.json'\n",
    "sentence_sentiment_path = '../data/newest_data(rolling update)/claim center and statistics/automos driving/stance_count.json'\n",
    "with open(sentence_sentiment_path, 'r') as f:\n",
    "    sentence_sentiment = json.load(f)\n",
    "\n",
    "for i in output_data:\n",
    "    key = i['content']\n",
    "    if not key in sentence_sentiment['neutral'] and not key in sentence_sentiment['positive'] and not key in sentence_sentiment['negative']:\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_output = {\n",
    "    'neutral' : {},\n",
    "    'positive' : {},\n",
    "    'negative' : {}\n",
    "}\n",
    "\n",
    "for key, value in sentence_sentiment.items():\n",
    "    for index, cs in enumerate(value):\n",
    "        o_index = next((i for i, s in enumerate(output_data) if s['content'] == cs), -1)\n",
    "        formated_output[key][f'claim_{index}'] = output_data[o_index]['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': {'claim_0': [('driverless', 0.5171),\n",
       "   ('driving', 0.4749),\n",
       "   ('uber', 0.3602),\n",
       "   ('traffic', 0.2889),\n",
       "   ('self', 0.2729),\n",
       "   ('safer', 0.2714),\n",
       "   ('blind', 0.2163),\n",
       "   ('guide', 0.1279),\n",
       "   ('crashes', 0.111),\n",
       "   ('average', 0.0119)],\n",
       "  'claim_1': [('driving', 0.4354),\n",
       "   ('parking', 0.38),\n",
       "   ('commuting', 0.3387),\n",
       "   ('self', 0.2139),\n",
       "   ('expensive', 0.1889),\n",
       "   ('cab', 0.1598),\n",
       "   ('unmanned', 0.1371),\n",
       "   ('san', 0.1347),\n",
       "   ('cool', 0.0521),\n",
       "   ('never', 0.0418)],\n",
       "  'claim_2': [('driving', 0.4886),\n",
       "   ('self', 0.3348),\n",
       "   ('legal', 0.1524),\n",
       "   ('safe', 0.1274),\n",
       "   ('urban', 0.11),\n",
       "   ('handle', 0.1008),\n",
       "   ('meetings', 0.0982),\n",
       "   ('emails', 0.0896),\n",
       "   ('would', 0.0499),\n",
       "   ('liabilities', 0.0466)],\n",
       "  'claim_3': [('automobiles', 0.4353),\n",
       "   ('autopilot', 0.3282),\n",
       "   ('dangers', 0.3203),\n",
       "   ('inattentive', 0.3114),\n",
       "   ('maintenance', 0.2775),\n",
       "   ('lifetimes', 0.2632),\n",
       "   ('dystopia', 0.2321),\n",
       "   ('mirror', 0.1936),\n",
       "   ('crashes', 0.1684),\n",
       "   ('react', 0.1157)]},\n",
       " 'positive': {'claim_0': [('driving', 0.4628),\n",
       "   ('cab', 0.2679),\n",
       "   ('autopilot', 0.1946),\n",
       "   ('pleasure', 0.1688),\n",
       "   ('lazy', 0.151),\n",
       "   ('philly', 0.1216),\n",
       "   ('would', 0.1184),\n",
       "   ('point', 0.0954),\n",
       "   ('i95', 0.075),\n",
       "   ('humans', 0.0514)],\n",
       "  'claim_1': [('parking', 0.4638),\n",
       "   ('driver', 0.2471),\n",
       "   ('dui', 0.1744),\n",
       "   ('self', 0.1713),\n",
       "   ('finding', 0.1331),\n",
       "   ('someday', 0.1242),\n",
       "   ('prevent', 0.1214),\n",
       "   ('insurance', 0.1195),\n",
       "   ('go', 0.0985),\n",
       "   ('especially', 0.0142)],\n",
       "  'claim_2': [('driving', 0.3784),\n",
       "   ('trust', 0.2985),\n",
       "   ('self', 0.2577),\n",
       "   ('insurance', 0.2211),\n",
       "   ('safer', 0.2043),\n",
       "   ('recharge', 0.1563),\n",
       "   ('useless', 0.0914),\n",
       "   ('maybe', 0.0823),\n",
       "   ('geniuses', 0.0657),\n",
       "   ('hotspot', 0.0609)]},\n",
       " 'negative': {'claim_0': [('ai', 0.4683),\n",
       "   ('driver', 0.4083),\n",
       "   ('distractions', 0.2498),\n",
       "   ('google', 0.2447),\n",
       "   ('performance', 0.2177),\n",
       "   ('persons', 0.1701),\n",
       "   ('average', 0.1606),\n",
       "   ('limitations', 0.1514),\n",
       "   ('mile', 0.1371),\n",
       "   ('instead', 0.1365)],\n",
       "  'claim_1': [('drivers', 0.3611),\n",
       "   ('development', 0.3308),\n",
       "   ('technicians', 0.2947),\n",
       "   ('autonomous', 0.2716),\n",
       "   ('mobile', 0.2558),\n",
       "   ('maintenance', 0.2548),\n",
       "   ('failures', 0.2348),\n",
       "   ('safety', 0.2323),\n",
       "   ('bug', 0.1666),\n",
       "   ('would', 0.0273)],\n",
       "  'claim_2': [('driving', 0.4106),\n",
       "   ('autonomously', 0.3898),\n",
       "   ('uber', 0.3527),\n",
       "   ('self', 0.3197),\n",
       "   ('safer', 0.2368),\n",
       "   ('navigating', 0.2304),\n",
       "   ('pedestrian', 0.2089),\n",
       "   ('generation', 0.17),\n",
       "   ('possibly', 0.0335),\n",
       "   ('slope', 0.0133)]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 30, 'negative': 19, 'neutral': 60}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_statistic = {}\n",
    "for stm, clm in sentence_sentiment.items():\n",
    "    if not stm in support_statistic:\n",
    "        support_statistic[stm] = 0\n",
    "    for c in clm:\n",
    "        support_statistic[stm] += len(claimCenter_premise[c])\n",
    "support_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0820'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "d1 = today.strftime(f'%m%d')\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_output_path = f'../data/newest_data(rolling update)/claim center and statistics/bitcoin investment/keywords_formatted_{d1}_1.json'\n",
    "formated_output_path = f'../data/newest_data(rolling update)/claim center and statistics/automos driving/keywords_formatted_{d1}_1.json'\n",
    "with open(formated_output_path, 'w') as f:\n",
    "    json.dump(formated_output, fp=f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "640cace4827df8bb8e1edb3566e4e979a7918609c95fe3eaf671877de41a29fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key word extraction algorithm for claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from helper_function import count_valid_posts, get_claims, get_premises\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid posts:  (41, 70)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/v4/Should-I-invest-in-Bitcoin_with_labels_v4_70_filled.json', 'r') as f:\n",
    "    file_content = json.load(f)\n",
    "print('Get valid posts: ', count_valid_posts(file_content))\n",
    "claims = get_claims(file_content)\n",
    "premises = get_premises(file_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword extraction algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keyword_extractor import TfIdfExtractor\n",
    "\n",
    "# if_idf = TfIdfExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if_idf.extract_keywords(premises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyBERT Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyword_extractor import KeyBERTExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keybert_extractor = KeyBERTExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keybert_extractor.extract_keywords(premises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Keywords under a certain center claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first build a list of supporting premises\n",
    "claims_with_support = {}\n",
    "for l in get_premises(file_content, return_list_of_strings=False):\n",
    "    # l is a list of dict objects\n",
    "    for o in l:\n",
    "        clm, prm = o['supportClaim'], o['content']\n",
    "        if not clm in claims_with_support:\n",
    "            claims_with_support[clm] = []\n",
    "        claims_with_support[clm].append(prm)\n",
    "\n",
    "claim_center_relation = {}\n",
    "for l in get_claims(file_content, return_list_of_strings=False):\n",
    "    # l is a list of dict objects\n",
    "    for o in l:\n",
    "        clm, sc = o['content'], o['claimCenter']\n",
    "        if not sc in claim_center_relation:\n",
    "            claim_center_relation[sc] = []\n",
    "        claim_center_relation[sc].append(clm)\n",
    "\n",
    "claimCenter_premise = {}\n",
    "for cs, c_list in claim_center_relation.items():\n",
    "    if not cs in claimCenter_premise:\n",
    "        claimCenter_premise[cs] = []\n",
    "    for c in c_list:\n",
    "        if c in claims_with_support:\n",
    "            claimCenter_premise[cs].extend(claims_with_support[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "for k,v in claimCenter_premise.items():\n",
    "    term = {\n",
    "        'content' : k,\n",
    "        'keywords' : []\n",
    "    }\n",
    "    kws = keybert_extractor.extract_keywords(' '.join(v), keep_term=10)\n",
    "    kws.sort(key=lambda a: a[1], reverse=True)\n",
    "    term['keywords'] = kws\n",
    "    output_data.append(term)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One of the proof cryptocurrencies are not ready yet, is the extremely fluctuating value that solely driven by “demand” and “potential”, instead of real-world implementation.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claimCenter_premise['It is almost certainly in a bubble.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = keybert_extractor.extract_keywords(' '.join(v), keep_term=15)\n",
    "# x.sort(key=lambda a : a[1])\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/newest_data(rolling update)/claim center and statistics/keywords.json', 'w') as f:\n",
    "    json.dump(output_data, fp=f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cryptocurrencies', 0.5732),\n",
       " ('diversified', 0.3917),\n",
       " ('minority', 0.2698),\n",
       " ('portfolio', 0.4366),\n",
       " ('risky', 0.2879),\n",
       " ('position', 0.1183),\n",
       " ('generally', 0.169),\n",
       " ('bitcoin', 0.4283),\n",
       " ('assets', 0.3653),\n",
       " ('well', 0.0483)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keybert_extractor.extract_keywords(\" \".join(claimCenter_premise['That’s up to you.']), keep_term=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_sentiment = {\n",
    "    'neutral' : [\n",
    "        \"It’s not too late to invest.\",\n",
    "        \"That’s up to you.\",\n",
    "        \"It depends what your level of disposable income is, how great your assets are, and what other assets you have invested in.\",\n",
    "        \"The significant thing is to do your own research and comprehend the dangers.\",\n",
    "        \"Invest in Bitcoin, only if you are okay to loss all.\",\n",
    "        \"Investing in Bitcoin is viable option especially in a view of current decline of the power of Fiat currencies.\",\n",
    "        \"If you are willing to take the risk, first make sure you understand what you are investing in and have a crypto investment strategy\",\n",
    "    ],\n",
    "    \"positive\" : [\n",
    "        \"I would say YES!\",\n",
    "        \"Of course you should\",\n",
    "    ],\n",
    "    \"negative\" : [\n",
    "        \"Bitcoin is pretty useless. But so is gold.\",\n",
    "        \"Cryto currency is an extremely high-hazard venture, and CFDs bought on margin are significantly more hazardous.\",\n",
    "        \"It is almost certainly in a bubble.\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i in output_data:\n",
    "    key = i['content']\n",
    "    if not key in sentence_sentiment['neutral'] and not key in sentence_sentiment['positive'] and not key in sentence_sentiment['negative']:\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_output = {\n",
    "    'neutral' : {},\n",
    "    'positive' : {},\n",
    "    'negative' : {}\n",
    "}\n",
    "\n",
    "for key, value in sentence_sentiment.items():\n",
    "    for index, cs in enumerate(value):\n",
    "        o_index = next((i for i, s in enumerate(output_data) if s['content'] == cs), -1)\n",
    "        format(key)[f'claim_{index}'] = output_data[o_index]['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "640cace4827df8bb8e1edb3566e4e979a7918609c95fe3eaf671877de41a29fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
